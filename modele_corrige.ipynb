{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c78d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbdc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chargement des données\n",
    "df = pd.read_excel(\"DATA_EX.xlsx\", engine='openpyxl')\n",
    "df.set_index('datetime', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95935628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes de données à utiliser pour la prédiction\n",
    "columns_to_predict = ['temp_max', 'temp_min', 'temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ce79b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données pour chaque station\n",
    "stations = df['station_id'].unique()\n",
    "models = {}\n",
    "for station in stations:\n",
    "    print(f\"Processing station {station}\")\n",
    "    df_station = df[df['station_id'] == station][columns_to_predict]\n",
    "    \n",
    "    # Normalisation des données\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df_station)\n",
    "\n",
    "    # Préparation des données d'entrée et de sortie pour le modèle LSTM\n",
    "    n_past = 30 # Nombre de jours passés utilisés pour la prédiction\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(n_past, len(df_station)):\n",
    "        X.append(scaled_data[i-n_past:i, :])\n",
    "        y.append(scaled_data[i, :])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y) # Définition du modèle LSTM\n",
    "    # Boucle pour tester chaque fonction de perte\n",
    "    for loss_func in loss_functions:\n",
    "        # Définition du modèle LSTM\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(168, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "        model.add(LSTM(168, return_sequences=False))\n",
    "        model.add(Dense(len(columns_to_predict)))\n",
    "\n",
    "        # Compilation du modèle avec la fonction de perte spécifique\n",
    "        model.compile(optimizer='adam', loss=loss_func)\n",
    "\n",
    "        # Entraînement du modèle\n",
    "        model.fit(X, y, epochs=1, batch_size=32, verbose=0)\n",
    "\n",
    "        # Évaluation du modèle sur les données de test (facultatif)\n",
    "        evaluation_result = model.evaluate(X, y)\n",
    "\n",
    "        # Stockage des résultats pour cette fonction de perte\n",
    "        results[str(loss_func)] = evaluation_result\n",
    "\n",
    "    # Affichage des résultats\n",
    "    for loss_func, result in results.items():\n",
    "        print(f\"Loss function: {loss_func}, Evaluation result: {result}\")\n",
    "    models[station] = {'model': model, 'scaler': scaler}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff29d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad311f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation des modèles pour prédire les données futures pour chaque station\n",
    "n_future = 5 # Nombre de jours à prédire\n",
    "forecasts = {}\n",
    "for station in stations:\n",
    "    print(f\"Predicting for station {station}\")\n",
    "    df_station = df[df['station_id'] == station][columns_to_predict]\n",
    "    scaler = models[station]['scaler']\n",
    "    model = models[station]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd02b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # Préparation des données d'entrée pour la prédiction\n",
    "inputs = df_station[-n_past:].values\n",
    "inputs = scaler.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2495ee2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Utilisation des modèles pour prédire les données futures pour chaque station\n",
    "n_future = 5 # Nombre de jours à prédire\n",
    "forecasts = {}\n",
    "for station in stations:\n",
    "    print(f\"Predicting for station {station}\")\n",
    "    df_station = df[df['station_id'] == station][columns_to_predict]\n",
    "    scaler = models[station]['scaler']\n",
    "    model = models[station]['model']\n",
    "\n",
    "    # Préparation des données d'entrée pour la prédiction\n",
    "    inputs = df_station[-n_past:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    # Prédiction pour les jours suivants\n",
    "    forecast = []\n",
    "    for i in range(n_future):\n",
    "        X_test = np.array([inputs])\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "        y_pred = model.predict(X_test)\n",
    "        forecast.append(y_pred[0])\n",
    "        inputs = np.vstack((inputs[1:], y_pred))\n",
    "\n",
    "    # Inverser la normalisation pour obtenir les prévisions originales\n",
    "    forecast = scaler.inverse_transform(forecast)\n",
    "    \n",
    "    # Ajouter les prévisions dans le dictionnaire des prévisions pour chaque station\n",
    "    forecasts[station] = pd.DataFrame(forecast, columns = columns_to_predict)\n",
    "    forecasts[station].index = pd.date_range(start='2023-01-01', periods=n_future, freq='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténer les prévisions de chaque station dans un seul DataFrame\n",
    "all_forecasts = pd.concat([forecasts[station] for station in stations], axis=1, keys=stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f15b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enregistrer les prévisions dans un fichier Excel\n",
    "all_forecasts.to_excel('all_forecasts_temp2.xlsx')\n",
    "print(\"Prévisions enregistrées dans 'all_forecasts.xlsx'\")\n",
    "\n",
    "# Visualiser les prévisions pour chaque station\n",
    "for station in stations:\n",
    "    forecast_df = forecasts[station]\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(15, 20))\n",
    "    for i, column in enumerate(columns_to_predict):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        axes[row, col].plot(df[df['station_id'] == station].index, df[df['station_id'] == station][column], label='Données réelles')\n",
    "        axes[row, col].plot(forecast_df.index, forecast_df[column], label='Prévisions')\n",
    "        axes[row, col].set_title(column)\n",
    "        axes[row, col].legend()\n",
    "    plt.suptitle(f\"Prévisions pour la station {station}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc695c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca947f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
